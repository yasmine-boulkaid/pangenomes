{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T07:54:09.492835Z",
     "start_time": "2024-06-19T07:54:07.755727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.stats import fisher_exact\n",
    "import bdsg\n",
    "import copy\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tests",
   "id": "221a95ac74c3705f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### test exact fisher ###\n",
    "table = np.array([[6, 2], [1, 4]])\n",
    "M = table.sum()\n",
    "n = table[0].sum()\n",
    "N = table[:, 0].sum()\n",
    "start, end = hypergeom.support(M, n, N)\n",
    "hypergeom.pmf(np.arange(start, end + 1), M, n, N)\n",
    "np.array([0.01631702, 0.16317016, 0.40792541, 0.32634033, 0.08158508, 0.004662])\n",
    "res = fisher_exact(table, alternative='two-sided')\n",
    "print(\"fisher : \", res.pvalue)"
   ],
   "id": "bb365a7db4184e1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# From VCF file\n",
    "## read vcf, create data frames"
   ],
   "id": "9b16a4c079a427d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# on va essayer de faire un giga tableau qui recense tous les chemins possibles -> OK (pour un éch mais normalement c'est les mêmes chemins possibles)\n",
    "# une fois qu'on aura fait ce giga tableau, on va essayer de le transformer en giga matrice qui compte pour 1 éch les chemins pris -> OK\n",
    "# une fois que ce sera fait on pourra transformer la giga matrice en giga table de contingence (?) qui recense la même chose mais pour tous les échantillons -> OK (dataframe)"
   ],
   "id": "b14fc2293a3cca30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# fonctions annexes pour créer le df qui contient les infos après avoir parse tous les vcf",
   "id": "9020d532723574b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CHROM    POS        ID                                                REF  \\\n",
       "0    ref    450      >1>4                                                  T   \n",
       "1    ref    578      >4>9  TTTGCGGGCCGTCAAGATGAACTGGTGCCTGTAGGATTATGTCCTC...   \n",
       "2    ref   1118     >9>12                                                  A   \n",
       "3    ref   1340    >12>14  GATCGGACTTCTTAACGGGTTCCTCACGTAGCGATCTCTACGGGAA...   \n",
       "4    ref   1529    >14>19                                                  C   \n",
       "..   ...    ...       ...                                                ...   \n",
       "95   ref  27003  >489>492                                                  C   \n",
       "96   ref  27134  >492>497                                                  A   \n",
       "97   ref  27275  >497>502  TGCAATAGTTTGCTCGTGGTCAGTATTTTCGGTATAAAACAGAGTT...   \n",
       "98   ref  27745  >502>507  CGGACATGTAGCAGGACTCCTTATAGTTAATGTTCACTATTTAAAG...   \n",
       "99   ref  28436  >507>512                                                  G   \n",
       "\n",
       "                                                  ALT     QUAL FILTER  \\\n",
       "0                                                   G  133.927   PASS   \n",
       "1   TTTGCGGGCCGTCAAGATGAACTGGTGCCTGTAGGATTATGTCCTC...  14.6171   PASS   \n",
       "2                                                   G  177.783   PASS   \n",
       "3                                                   G  116.981   PASS   \n",
       "4   CCCGATCTATGTCGAGGCTTTCGGGCAGGGCCGCTATTAACATCGT...    175.5   PASS   \n",
       "..                                                ...      ...    ...   \n",
       "95                                                  T  411.605   PASS   \n",
       "96  ATACACTAGACGCCCGGGATGTACATATCGTGACTCGTTCCTAGTC...  145.789   PASS   \n",
       "97  T,TGCAATAGTTTGCTCGTGGTCAGTATTTTCGGTATAAAACAGAG...  371.786   PASS   \n",
       "98  CGGACATGTAGCAGGACTCCTTATAGTTAATGTTCACTATTTAAAG...  122.081   PASS   \n",
       "99  GATCTCGTCTGACATCACTTGAATTCTTATATTAGTTCTAAACTTC...  128.002   PASS   \n",
       "\n",
       "                                                 INFO  \\\n",
       "0                              AT=>1>2>4,>1>3>4;DP=46   \n",
       "1                      AT=>4>5>7>8>9,>4>5>6>8>9;DP=50   \n",
       "2                          AT=>9>11>12,>9>10>12;DP=61   \n",
       "3                           AT=>12>13>14,>12>14;DP=47   \n",
       "4     AT=>14>19,>14>15>17>18>19,>14>15>16>18>19;DP=60   \n",
       "..                                                ...   \n",
       "95                 AT=>489>490>492,>489>491>492;DP=43   \n",
       "96  AT=>492>497,>492>493>495>496>497,>492>493>494>...   \n",
       "97  AT=>497>498>500>501>502,>497>502,>497>498>499>...   \n",
       "98  AT=>502>503>504>506>507,>502>503>505>506>507,>...   \n",
       "99  AT=>507>512,>507>508>509>511>512,>507>508>510>...   \n",
       "\n",
       "                      FORMAT  \\\n",
       "0   GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "1   GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "2   GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "3   GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "4   GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "..                       ...   \n",
       "95  GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "96  GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "97  GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "98  GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "99  GT:DP:AD:GL:GQ:GP:XD:MAD   \n",
       "\n",
       "                                               SAMPLE  \n",
       "0   0/0:46:46,0:-2.378747,-15.294357,-107.194421:1...  \n",
       "1   1/0:50:25,25:-3.306431,-2.422690,-3.306431:16:...  \n",
       "2   0/0:61:61,0:-2.701171,-20.002352,-141.869830:1...  \n",
       "3   0/0:47:46,1:-2.770745,-13.991746,-90.540504:11...  \n",
       "4   0/0:60:60,0,0:-2.835631,-19.908524,-19.908524,...  \n",
       "..                                                ...  \n",
       "95  1/0:43:20,23:-43.061833,-2.378411,-35.907321:2...  \n",
       "96  0/0:50:50,0,0:-2.439843,-16.541658,-16.541658,...  \n",
       "97  1/2:52:2,24,27:-39.603567,-3.504039,-35.913027...  \n",
       "98  0/0:42:42,0,0:-2.420888,-14.151905,-14.151905,...  \n",
       "99  0/0:44:44,0,0:-2.374808,-14.697901,-14.697901,...  \n",
       "\n",
       "[100 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>INFO</th>\n",
       "      <th>FORMAT</th>\n",
       "      <th>SAMPLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ref</td>\n",
       "      <td>450</td>\n",
       "      <td>&gt;1&gt;4</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>133.927</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;1&gt;2&gt;4,&gt;1&gt;3&gt;4;DP=46</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:46:46,0:-2.378747,-15.294357,-107.194421:1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ref</td>\n",
       "      <td>578</td>\n",
       "      <td>&gt;4&gt;9</td>\n",
       "      <td>TTTGCGGGCCGTCAAGATGAACTGGTGCCTGTAGGATTATGTCCTC...</td>\n",
       "      <td>TTTGCGGGCCGTCAAGATGAACTGGTGCCTGTAGGATTATGTCCTC...</td>\n",
       "      <td>14.6171</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;4&gt;5&gt;7&gt;8&gt;9,&gt;4&gt;5&gt;6&gt;8&gt;9;DP=50</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>1/0:50:25,25:-3.306431,-2.422690,-3.306431:16:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ref</td>\n",
       "      <td>1118</td>\n",
       "      <td>&gt;9&gt;12</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>177.783</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;9&gt;11&gt;12,&gt;9&gt;10&gt;12;DP=61</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:61:61,0:-2.701171,-20.002352,-141.869830:1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ref</td>\n",
       "      <td>1340</td>\n",
       "      <td>&gt;12&gt;14</td>\n",
       "      <td>GATCGGACTTCTTAACGGGTTCCTCACGTAGCGATCTCTACGGGAA...</td>\n",
       "      <td>G</td>\n",
       "      <td>116.981</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;12&gt;13&gt;14,&gt;12&gt;14;DP=47</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:47:46,1:-2.770745,-13.991746,-90.540504:11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ref</td>\n",
       "      <td>1529</td>\n",
       "      <td>&gt;14&gt;19</td>\n",
       "      <td>C</td>\n",
       "      <td>CCCGATCTATGTCGAGGCTTTCGGGCAGGGCCGCTATTAACATCGT...</td>\n",
       "      <td>175.5</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;14&gt;19,&gt;14&gt;15&gt;17&gt;18&gt;19,&gt;14&gt;15&gt;16&gt;18&gt;19;DP=60</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:60:60,0,0:-2.835631,-19.908524,-19.908524,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ref</td>\n",
       "      <td>27003</td>\n",
       "      <td>&gt;489&gt;492</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>411.605</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;489&gt;490&gt;492,&gt;489&gt;491&gt;492;DP=43</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>1/0:43:20,23:-43.061833,-2.378411,-35.907321:2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ref</td>\n",
       "      <td>27134</td>\n",
       "      <td>&gt;492&gt;497</td>\n",
       "      <td>A</td>\n",
       "      <td>ATACACTAGACGCCCGGGATGTACATATCGTGACTCGTTCCTAGTC...</td>\n",
       "      <td>145.789</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;492&gt;497,&gt;492&gt;493&gt;495&gt;496&gt;497,&gt;492&gt;493&gt;494&gt;...</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:50:50,0,0:-2.439843,-16.541658,-16.541658,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ref</td>\n",
       "      <td>27275</td>\n",
       "      <td>&gt;497&gt;502</td>\n",
       "      <td>TGCAATAGTTTGCTCGTGGTCAGTATTTTCGGTATAAAACAGAGTT...</td>\n",
       "      <td>T,TGCAATAGTTTGCTCGTGGTCAGTATTTTCGGTATAAAACAGAG...</td>\n",
       "      <td>371.786</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;497&gt;498&gt;500&gt;501&gt;502,&gt;497&gt;502,&gt;497&gt;498&gt;499&gt;...</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>1/2:52:2,24,27:-39.603567,-3.504039,-35.913027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ref</td>\n",
       "      <td>27745</td>\n",
       "      <td>&gt;502&gt;507</td>\n",
       "      <td>CGGACATGTAGCAGGACTCCTTATAGTTAATGTTCACTATTTAAAG...</td>\n",
       "      <td>CGGACATGTAGCAGGACTCCTTATAGTTAATGTTCACTATTTAAAG...</td>\n",
       "      <td>122.081</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;502&gt;503&gt;504&gt;506&gt;507,&gt;502&gt;503&gt;505&gt;506&gt;507,&gt;...</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:42:42,0,0:-2.420888,-14.151905,-14.151905,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ref</td>\n",
       "      <td>28436</td>\n",
       "      <td>&gt;507&gt;512</td>\n",
       "      <td>G</td>\n",
       "      <td>GATCTCGTCTGACATCACTTGAATTCTTATATTAGTTCTAAACTTC...</td>\n",
       "      <td>128.002</td>\n",
       "      <td>PASS</td>\n",
       "      <td>AT=&gt;507&gt;512,&gt;507&gt;508&gt;509&gt;511&gt;512,&gt;507&gt;508&gt;510&gt;...</td>\n",
       "      <td>GT:DP:AD:GL:GQ:GP:XD:MAD</td>\n",
       "      <td>0/0:44:44,0,0:-2.374808,-14.697901,-14.697901,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2,
   "source": [
    "# read ONE vcf file\n",
    "\n",
    "def create_vcf_df(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [l for l in f if not l.startswith('##')]\n",
    "    return pd.read_csv(\n",
    "        io.StringIO(''.join(lines)),\n",
    "        dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str,\n",
    "               'QUAL': str, 'FILTER': str, 'INFO': str},\n",
    "        sep='\\t'\n",
    "    ).rename(columns={'#CHROM': 'CHROM'})\n",
    "\n",
    "# verification de la fonction read_vcf \n",
    "vcf1_df = create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/samp_g0_0.vcf\")\n",
    "vcf1_df"
   ],
   "id": "6ab0490ec5faa08e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:09:41.964861Z",
     "start_time": "2024-06-19T09:09:41.695521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read all vcf files and store them in a list\n",
    "\n",
    "all_vcf = os.listdir(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\")\n",
    "g0_vcf =  []\n",
    "g1_vcf = []\n",
    "for i in all_vcf:\n",
    "    if 'g0' in i:\n",
    "        g0_vcf.append(i)\n",
    "    elif 'g1' in i:\n",
    "        g1_vcf.append(i)\n",
    "all_vcf_df = [create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\"+i) for i in all_vcf]\n",
    "g0_vcf_df = [create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\"+i) for i in g0_vcf]\n",
    "g1_vcf_df = [create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\"+i) for i in g1_vcf]"
   ],
   "id": "53c6135da34640b2",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "# old\n",
    "\n",
    "def chemins(which_vcf_df):    \n",
    "    chemins_possibles = []\n",
    "    for i in range(len(which_vcf_df[\"INFO\"])):\n",
    "        text = which_vcf_df[\"INFO\"][i]\n",
    "        m = re.search('AT=>(.+?);DP', text)\n",
    "        if m:\n",
    "            found = m.group(1)\n",
    "        chemins_possibles.append(found)\n",
    "        \n",
    "    for i in range(len(chemins_possibles)):\n",
    "        chemins_possibles[i] = chemins_possibles[i].split(',')\n",
    "        \n",
    "    ########################################################################\n",
    "    chemins_pris = []\n",
    "    for i in which_vcf_df[\"SAMPLE\"]:\n",
    "        found = i[0:3]\n",
    "        chemins_pris.append(found)\n",
    "    \n",
    "    for i in range(len(chemins_pris)):\n",
    "        chemins_pris[i] = chemins_pris[i].split('/')\n",
    "        for j in range(len(chemins_pris[i])):\n",
    "            chemins_pris[i][j] = int(chemins_pris[i][j])\n",
    "            \n",
    "    ########################################################################\n",
    "    chemins_combines = copy.deepcopy(chemins_pris)\n",
    "    \n",
    "    for i in range(len(chemins_pris)):\n",
    "        chemins_combines[i][0] = chemins_possibles[i][chemins_pris[i][0]]\n",
    "        chemins_combines[i][1] = chemins_possibles[i][chemins_pris[i][1]]\n",
    "        \n",
    "    ''' cas simple pour comprendre\n",
    "    print(chemins_pris[0])\n",
    "    chemins_pris[0][0] = chemins_possibles[0][chemins_pris[0][0]]\n",
    "    chemins_pris[0][1] = chemins_possibles[0][chemins_pris[0][1]]\n",
    "    print(chemins_pris[0])'''\n",
    "    \n",
    "    chemins_possibles = sum(chemins_possibles, [])\n",
    "    chemins_pris = sum(chemins_pris, [])\n",
    "    chemins_combines = sum(chemins_combines, [])\n",
    "    \n",
    "    return chemins_possibles, chemins_pris, chemins_combines"
   ],
   "id": "6f1297b77b958959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== possibles ==========\n",
      "['1>2>4', '>1>3>4', '4>5>7>8>9', '>4>5>6>8>9', '9>11>12']\n",
      "============ pris =============\n",
      "[0, 0, 1, 0, 0]\n",
      "========== combinés ===========\n",
      "['1>2>4', '1>2>4', '>4>5>6>8>9', '4>5>7>8>9', '9>11>12']\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "chemins_possibles1, chemins_pris1, chemins_combines1 = chemins(vcf1_df)\n",
    "print('========== possibles ==========')\n",
    "print(chemins_possibles1[0:5])\n",
    "print('============ pris =============')\n",
    "print(chemins_pris1[0:5])\n",
    "print('========== combinés ===========')\n",
    "print(chemins_combines1[0:5])"
   ],
   "id": "ada6cdb956d0b3b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ici",
   "id": "161861c7ff026268"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:46:54.951606Z",
     "start_time": "2024-06-19T12:46:54.947278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''def chemins(vcf_df):\n",
    "    chemins_possibles = []\n",
    "    for i in range(len(vcf_df[\"INFO\"])):\n",
    "        text = vcf_df[\"INFO\"][i]\n",
    "        m = re.search('AT=>(.+?);DP', text)\n",
    "        if m:\n",
    "            found = m.group(1)\n",
    "        chemins_possibles.append(found)\n",
    "        \n",
    "    for i in range(len(chemins_possibles)):\n",
    "        chemins_possibles[i] = chemins_possibles[i].split(',')\n",
    "        \n",
    "    ########################################################################\n",
    "    chemins_pris = []\n",
    "    for i in vcf_df[\"SAMPLE\"]:\n",
    "        found = i[0:3]\n",
    "        chemins_pris.append(found)\n",
    "    \n",
    "    for i in range(len(chemins_pris)):\n",
    "        chemins_pris[i] = chemins_pris[i].split('/')\n",
    "        for j in range(len(chemins_pris[i])):\n",
    "            chemins_pris[i][j] = int(chemins_pris[i][j])\n",
    "            \n",
    "    ########################################################################\n",
    "    chemins_combines = copy.deepcopy(chemins_pris)\n",
    "    \n",
    "    for i in range(len(chemins_pris)):\n",
    "        chemins_combines[i][0] = chemins_possibles[i][chemins_pris[i][0]]\n",
    "        chemins_combines[i][1] = chemins_possibles[i][chemins_pris[i][1]]\n",
    "        \n",
    "    chemins_possibles = sum(chemins_possibles, [])\n",
    "    chemins_pris = sum(chemins_pris, [])\n",
    "    chemins_combines = sum(chemins_combines, [])\n",
    "    #chemins_finaux = [[i,chemins_combines.count(i)] for i in set(chemins_combines)]\n",
    "    \n",
    "    return chemins_possibles, chemins_pris, chemins_combines, chemins_finaux\n",
    "\n",
    "path = \"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\"\n",
    "all_vcf_df = [create_vcf_df(path+i) for i in all_vcf]\n",
    "\n",
    "chemins_possibles = [chemins(i)[0] for i in all_vcf_df]\n",
    "# chemins_possibles = sum(chemins_possibles, [])\n",
    "# chemins_possibles = list(set(chemins_possibles))\n",
    "chemins_pris = [chemins(i)[1] for i in all_vcf_df]\n",
    "chemins_combines = [chemins(i)[2] for i in all_vcf_df]\n",
    "chemins_finaux = [chemins(i)[3] for i in all_vcf_df]\n",
    "\n",
    "''''''chemins_combines = sum(chemins_combines, [])\n",
    "chemins_finaux = [[i,chemins_combines.count(i)] for i in set(chemins_combines)]''' '''''';"
   ],
   "id": "8fe42a4f4d3b69d1",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:23:57.565124Z",
     "start_time": "2024-06-19T09:23:57.552040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vcf2_df = create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/samp_g0_1.vcf\")\n",
    "vcf3_df = create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/samp_g1_1.vcf\")\n",
    "\n",
    "def chemins_finaux(vcf_df_list):\n",
    "    chemins_finaux = []\n",
    "    for i in range(len(vcf_df_list)):\n",
    "        chemins_aux = []\n",
    "        chemins_possibles, chemins_pris, chemins_combines = chemins(vcf_df_list[i])\n",
    "        for j in set(chemins_combines):\n",
    "            chemins_aux.append([j,chemins_combines.count(j)])\n",
    "        chemins_finaux.append(chemins_aux)\n",
    "    return chemins_finaux\n",
    "\n",
    "print(chemins_finaux([vcf1_df]))"
   ],
   "id": "c06655f1219f25d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['136>147', 2], ['111>116', 2], ['>466>467>468>470>471', 1], ['125>127>128', 2], ['261>262>263', 2], ['478>479>481', 1], ['>313>315', 1], ['89>91>92', 1], ['>28>29>31', 2], ['269>270>272', 2], ['>60>61>62>64>65>67>69>70>71', 1], ['>427>428>429>431>432>434>435>437>438', 2], ['25>27>28', 2], ['422>424>425', 1], ['251>252>254', 2], ['12>13>14', 2], ['9>11>12', 2], ['>187>188>189>191>192', 1], ['239>240>242', 2], ['>46>47>48>50>51>53>54>56>57>59>60', 2], ['41>43', 1], ['>403>404>405>407>409>410>411>413>414>416>417', 1], ['417>418>419>421>422', 1], ['254>255>256', 2], ['152>153>154', 2], ['313>314>315', 1], ['184>185>187', 2], ['248>250>251', 1], ['>4>5>6>8>9', 1], ['>19>20>22', 1], ['4>5>7>8>9', 1], ['>79>84', 1], ['>452>466', 1], ['>128>129>131>132>133', 1], ['14>19', 2], ['337>351', 1], ['>122>123>125', 1], ['170>171>173', 2], ['449>450>452', 1], ['103>104>106>107>108>110>111', 1], ['334>335>337', 1], ['>204>205>206>208>209>211>213>214>215>217>219>220>221>223>224>226>228>229>230>232>234>235>236>238>239', 2], ['471>472>473', 2], ['>334>336>337', 1], ['192>194>195', 2], ['>22>23>25', 1], ['>74>76>77', 1], ['331>333>334', 2], ['486>488>489', 2], ['310>312>313', 2], ['>119>121>122', 2], ['>178>179>181', 2], ['502>503>504>506>507', 2], ['>41>42>43', 1], ['272>274>275', 2], ['>466>471', 1], ['181>182>184', 2], ['288>293', 1], ['>449>451>452', 1], ['>43>45>46', 2], ['195>197>198', 2], ['>248>249>251', 1], ['329>331', 2], ['71>73>74', 2], ['>478>480>481', 1], ['489>490>492', 1], ['74>75>77', 1], ['403>417', 1], ['444>445>446', 1], ['95>96>97>99>100', 1], ['263>265>266', 1], ['>337>338>340>341>342>344>345>347>349>350>351', 1], ['>438>440>441', 2], ['>187>188>190>191>192', 1], ['>275>286', 2], ['156>157>159', 2], ['307>309>310', 1], ['>128>133', 1], ['>417>418>420>421>422', 1], ['173>174>176', 1], ['>481>482>484>485>486', 2], ['266>268>269', 1], ['>89>90>92', 1], ['>444>446', 1], ['507>512', 2], ['475>476>478', 2], ['>266>267>269', 1], ['286>287>288', 2], ['315>316>317>319>320>322>324>325>327>328>329', 2], ['31>32>34', 2], ['>95>100', 1], ['473>474>475', 2], ['>103>104>105>107>109>110>111', 1], ['>497>498>499>501>502', 1], ['441>443>444', 2], ['>307>308>310', 1], ['>173>175>176', 1], ['>489>491>492', 1], ['>263>264>266', 1], ['1>2>4', 2], ['>422>423>425', 1], ['>293>294>295>297>298>300>302>303>304>306>307', 2], ['60>61>63>64>65>67>68>70>71', 1], ['79>80>81>83>84', 1], ['380>403', 2], ['116>118>119', 2], ['201>203>204', 2], ['84>89', 2], ['>497>502', 1], ['>425>427', 2], ['351>380', 2], ['34>35>36>38>39', 2], ['>147>148>150>151>152', 1], ['133>134>136', 2], ['>176>177>178', 2], ['>256>257>259>260>261', 2], ['446>448>449', 2], ['22>24>25', 1], ['>198>200>201', 2], ['92>93>95', 2], ['159>170', 2], ['245>247>248', 2], ['19>21>22', 1], ['452>453>454>456>457>459>461>462>463>465>466', 1], ['77>78>79', 2], ['147>152', 1], ['>288>289>291>292>293', 1], ['122>124>125', 1], ['492>497', 2], ['154>156', 2], ['39>41', 2], ['100>101>103', 2], ['242>243>245', 2]]]\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:13:19.082653Z",
     "start_time": "2024-06-19T14:13:19.075972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_df(which_vcf_list):\n",
    "    chem_fin = chemins_finaux(which_vcf_list)\n",
    "    df = pd.DataFrame(columns=['snarl index', 'snarl', 'times taken','index provisoire'])\n",
    "    # df['times taken'] = 0 # je sais vraiment pas pourquoi ça marche plus ce machin \n",
    "    #df = df.assign(times_taken = 0)\n",
    "\n",
    "    chemins_possibles = [chemins(i)[0] for i in all_vcf_df]\n",
    "    chemins_possibles = sum(chemins_possibles, [])\n",
    "    chemins_possibles = list(set(chemins_possibles))\n",
    "    for i in range(len(chemins_possibles)):\n",
    "        df.loc[i, 'times taken'] = 0\n",
    "\n",
    "    df['snarl'] = chemins_possibles\n",
    "    \n",
    "    #########################################################################################\n",
    "    ################################### le pb vient de là ###################################\n",
    "    #########################################################################################\n",
    "    for i in which_vcf_list:\n",
    "        chemins_combines = chemins(i)[2]\n",
    "        combine_count = list((x,chemins_combines.count(x)) for x in set(chemins_combines))\n",
    "        for j in range(len(combine_count)):\n",
    "            #print(combine_count[j][0])\n",
    "            #print('1>2>4' in df['snarl'].unique())\n",
    "            if combine_count[j][0] in df['snarl'].unique():\n",
    "                df.loc[j, \"times taken\"] += combine_count[j][1]\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "\n",
    "    \n",
    "    '''for i in chem_fin[0][j][0]:\n",
    "        if i in df['snarl']:\n",
    "            df.loc[i, 'times taken'] += chem_fin[]'''\n",
    "    \n",
    "    \n",
    "    '''for i in range(len(chem_fin)):\n",
    "        for j in range(len(chem_fin[i])):\n",
    "            if chem_fin[i][j][0] in df['snarl']:\n",
    "                #df.loc[j, 'snarl'] = chem_fin[i][j][0]\n",
    "                df.loc[j, 'times taken'] += chem_fin[i][j][1]'''\n",
    "    \n",
    "    # fill 'snarl index' column\n",
    "    for i in range(len(df['snarl index'])):\n",
    "        if df['snarl'][i][0] == '>':\n",
    "            S = re.search('>(.+?)>', df['snarl'][i])\n",
    "            if S:\n",
    "                s = S.group(1)\n",
    "            E = re.search('.+>(.*)', df['snarl'][i])\n",
    "            if E:\n",
    "                e = E.group(1)\n",
    "            df.loc[i, \"snarl index\"] = s + '>' + e  \n",
    "            df.loc[i, \"index provisoire\"] = int(s)\n",
    "        else:\n",
    "            S = re.search('(.+?)>', df['snarl'][i])\n",
    "            if S:\n",
    "                s = S.group(1)\n",
    "            E = re.search('.+>(.*)', df['snarl'][i])\n",
    "            if E:\n",
    "                e = E.group(1)\n",
    "            df.loc[i, \"snarl index\"] = s + '>' + e\n",
    "            df.loc[i, \"index provisoire\"] = int(s)\n",
    "    \n",
    "    #df.set_index('snarl index', inplace=True, drop=True)\n",
    "    df.set_index('index provisoire', inplace=True, drop=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.reset_index()\n",
    "    df.set_index('snarl index', inplace=True, drop=True)\n",
    "    return df"
   ],
   "id": "1857b24902d56af8",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#commentaires bizarres je sais pas où les placer\n",
    "\n",
    "# on refait la même chose mais pour tous les VCF \n",
    "# création d'un df avec autant de lignes que de fichiers VCF \n",
    "# et mtn qu'on a un tout beau data frame on peut faire tout pareil mais en parsant tous les VCF :D \n",
    "# on refait pareil mais en séparant les groupes g0 et g1"
   ],
   "id": "c8bbcd17f0adc08c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''def times_taken(chemins_possibles, chemins_pris, chemins_combines, df):    \n",
    "    combine_count = list((x,chemins_combines.count(x)) for x in set(chemins_combines))\n",
    "    #print(combine_count)\n",
    "    for i in range(len(combine_count)):\n",
    "        for j in range(len(chemins_pris)):\n",
    "            if combine_count[i][0] == str(df['snarl'].iloc[j]):\n",
    "                df.loc[j, \"times taken\"] += combine_count[i][1]'''\n",
    "    "
   ],
   "id": "7642b16d59419ea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# là",
   "id": "4f2d595820835689"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:15:08.777561Z",
     "start_time": "2024-06-19T14:15:05.745330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# complete df\n",
    "# c'est pas bon, je peux pas avoir des times taken = 90 alors que j'ai que 60 individus\n",
    "# c'est vraiment vraiment n'importe quoi \n",
    "snarl_df = create_df(all_vcf_df)\n",
    "snarl_df\n",
    "#print(len(all_vcf_df))"
   ],
   "id": "837d98c2ef6ebe41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            snarl times taken\n",
       "snarl index                                  \n",
       "1>4                         1>2>4          91\n",
       "1>4                        >1>3>4           0\n",
       "4>9                          >4>9          90\n",
       "4>9                    >4>5>6>8>9           0\n",
       "4>9                     4>5>7>8>9           0\n",
       "...                           ...         ...\n",
       "502>507       502>503>504>506>507          17\n",
       "502>507                  >502>507          13\n",
       "507>512                   507>512          85\n",
       "507>512      >507>508>509>511>512           0\n",
       "507>512      >507>508>510>511>512           0\n",
       "\n",
       "[413 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snarl</th>\n",
       "      <th>times taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snarl index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1&gt;4</th>\n",
       "      <td>1&gt;2&gt;4</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1&gt;4</th>\n",
       "      <td>&gt;1&gt;3&gt;4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4&gt;9</th>\n",
       "      <td>&gt;4&gt;9</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4&gt;9</th>\n",
       "      <td>&gt;4&gt;5&gt;6&gt;8&gt;9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4&gt;9</th>\n",
       "      <td>4&gt;5&gt;7&gt;8&gt;9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502&gt;507</th>\n",
       "      <td>502&gt;503&gt;504&gt;506&gt;507</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502&gt;507</th>\n",
       "      <td>&gt;502&gt;507</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507&gt;512</th>\n",
       "      <td>507&gt;512</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507&gt;512</th>\n",
       "      <td>&gt;507&gt;508&gt;509&gt;511&gt;512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507&gt;512</th>\n",
       "      <td>&gt;507&gt;508&gt;510&gt;511&gt;512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# vcf_df = [create_vcf_df(\"/home/yboulkaid/Documents/sample_data/pgtest.data/calls/\"+i) for i in all_vcf]",
   "id": "f5968f4b006dba76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# group0 df\n",
    "g0_df = create_df(g0_vcf)\n",
    "g0_df"
   ],
   "id": "c1c5daf296b60d4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# group1 df\n",
    "g1_df = create_df(g1_vcf)\n",
    "g1_df"
   ],
   "id": "84a8161edbd60308",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pvaleurs aaaaah",
   "id": "5cfdfca16eedd01f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#snarl_df.index.value_counts()['4>9']\n",
    "len(chemins_possibles)"
   ],
   "id": "69d17b1e1a66bc18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mtn on utilise g0_df et g1_df pour créer des tables de contingences (en précisant pour quel snarl on veut créer la table)\n",
    "# old\n",
    "def table_contingence(which_snarl):\n",
    "    n = snarl_df.index.value_counts()[which_snarl]\n",
    "    print(n)\n",
    "    chem = []\n",
    "    for i in range(n):\n",
    "        chem.append(g0_df.loc[which_snarl]['snarl'].iloc[i])\n",
    "        print(chem)\n",
    "        #thing.append(g0_df.loc[which_snarl]['snarl'][i])\n",
    "        # corpus_df.loc['it'][1]\n",
    "    '''df2 = pd.DataFrame(columns=['g0', 'g1'], index=chem)\n",
    "    for i in range(len(chem)):\n",
    "        df2.at[chem[i], 'g1'] = g1_df.loc[which_snarl]['times taken'].iloc[i]\n",
    "        df2.at[chem[i], 'g0'] = g0_df.loc[which_snarl]['times taken'].iloc[i]\n",
    "    return df2'''\n",
    "    \n",
    "table_contingence('1>4')\n",
    "\n",
    "def chi2(table):\n",
    "    return chi2_contingency(table).pvalue"
   ],
   "id": "62a36584f68b56a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# mtn on utilise g0_df et g1_df pour créer des tables de contingences (en précisant pour quel snarl on veut créer la table)\n",
    "# new and not yet improved\n",
    "\n",
    "def table_contingence(which_snarl):\n",
    "    '''chem = []\n",
    "    for i in '''\n",
    "    df2 = pd.DataFrame(columns=['g0', 'g1'])#, index=chem)\n",
    "    \n",
    "\n",
    "print(table_contingence('1>4'))\n",
    "\n",
    "def chi2(table):\n",
    "    return chi2_contingency(table).pvalue"
   ],
   "id": "ceb0f52356ae44d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pval = []\n",
    "zero_dans_contingence_snarl = [] \n",
    "for i in snarl_df.index.unique():\n",
    "    #if 0 not in table_contingence(i).values:\n",
    "        #print(i)\n",
    "        #table = table_contingence(i)\n",
    "    pval.append([chi2(table_contingence(i)), i])\n",
    "        #print(i, 'ok')\n",
    "    #else:\n",
    "        #pval.append(-1)\n",
    "    #    zero_dans_contingence_snarl.append(i)\n",
    "print(zero_dans_contingence_snarl)"
   ],
   "id": "178821abd3bc518",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_pval_df(pval_list):\n",
    "    pval_df = pd.DataFrame(columns=['snarl index', 'p-valeur', 'moinslog10pvaleur', 'color'])\n",
    "    for i in range(len(pval_list)):\n",
    "        pval_df.loc[i, 'snarl index'] = pval_list[i][1]\n",
    "        pval_df.loc[i, \"p-valeur\"] = pval_list[i][0]\n",
    "        pval_df.loc[i, \"moinslog10pvaleur\"] = -np.log10(pval_list[i][0])\n",
    "    pval_df.set_index('snarl index', inplace=True, drop=True)\n",
    "    conditions = [\n",
    "        (pval_df['moinslog10pvaleur'] == 0.0001),\n",
    "        (pval_df['moinslog10pvaleur'] > 2),\n",
    "        (pval_df['moinslog10pvaleur'] < 2)]\n",
    "    choices = ['red', 'green', 'blue']\n",
    "    pval_df['color'] = np.select(conditions, choices, default='red')\n",
    "\n",
    "    return pval_df"
   ],
   "id": "1976d9a2599dfae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pv_df_test = create_pval_df(pval)\n",
    "#plt.hist(pval_df['p-valeur'])\n",
    "plt.hist(pv_df_test['p-valeur'])"
   ],
   "id": "22b317313195de23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# la p-valeur est égale à 1 quand on passe (quasiment) exactement autant de fois par un chemin que par l'autre\n",
    "\n",
    "for i in range(len(pval)):\n",
    "    if pval[i][0] == 1:\n",
    "        print(table_contingence(pval[i][1]))"
   ],
   "id": "b328db52f8a8e64b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "''' print(table_contingence(i))\n",
    "print(table_contingence(i).sum(axis = 0))\n",
    "print(contingence_pb[i])''' \n",
    "\n",
    "    \n",
    "'''print(len(snarl_index_somme_pas_ok))\n",
    "print(snarl_index_somme_pas_ok)\n",
    "for i in snarl_index_somme_pas_ok:\n",
    "    if i in zero_dans_contingence_snarl:\n",
    "        print(i)'''\n",
    "\n",
    "'''    print('--------------------')\n",
    "    print(contingence_pb[i])\n",
    "    print('####################')''';"
   ],
   "id": "c1f54ff0f76f802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# manhattan plot\n",
    "\n",
    "#fig = plt.figure(figsize=(14, 8)) \n",
    "#ax = fig.add_subplot(111)\n",
    "plt.scatter(range(len(pv_df_test)), pv_df_test['moinslog10pvaleur'], c=pv_df_test['color'])\n",
    "#ax.set_xlabel('snarl index')\n",
    "#ax.set_ylabel('moins log10 pvalue')\n"
   ],
   "id": "b8fbfacf02918012",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# find the smallest pvalues and the associated snarls   \n",
    "\n",
    "for i in range(len(pv_df_test)):\n",
    "    if pv_df_test['moinslog10pvaleur'].iloc[i] > 2:\n",
    "    # if pval_df.index[i] == '446>449':\n",
    "        # print(pval_df['moinslog10pvaleur'].iloc[i])\n",
    "        print('##########', pv_df_test['moinslog10pvaleur'].iloc[i])\n",
    "        print(table_contingence(pv_df_test.index[i]))"
   ],
   "id": "85b4368062ad9b24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# snarl untrue ? donne des meilleurs noms à tes variables \n",
    "\n",
    "snarl_untrue = ['198>201', '201>204', '427>438', '497>502']\n",
    "for i in range(len(pv_df_test.index)):\n",
    "    if pv_df_test.index[i] in snarl_untrue:\n",
    "        print('##############', pv_df_test.index[i], ';',  pv_df_test['moinslog10pvaleur'].iloc[i])  \n",
    "        print(table_contingence(pv_df_test.index[i]))\n"
   ],
   "id": "7200c200351c5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# trafiquer les tables de contingences \n",
    "## on ne veut plus de 0 dans les tables\n",
    "## on veut pas changer les effectifs par colonnes \n",
    "\n",
    "contingence_pb = [table_contingence(i) for i in zero_dans_contingence_snarl]\n",
    "snarl_index_somme_pas_ok = []\n",
    "\n",
    "'''for i in snarl_df.index.unique():\n",
    "    if table_contingence(i).sum(axis = 0).iloc[0] != 60 or table_contingence(i).sum(axis = 0).iloc[1] != 60:\n",
    "        snarl_index_somme_pas_ok.append(i)'''\n",
    "for i in range(len(contingence_pb)):\n",
    "    contingence_pb[i] = contingence_pb[i].where(contingence_pb[i] != 0, contingence_pb[i]+1)\n",
    "    contingence_pb[i] = contingence_pb[i].where(contingence_pb[i] != contingence_pb[i].max().max(), contingence_pb[i]-1)\n",
    "''' print(table_contingence(i))\n",
    "print(table_contingence(i).sum(axis = 0))\n",
    "print(contingence_pb[i])''' \n",
    "\n",
    "    \n",
    "'''print(len(snarl_index_somme_pas_ok))\n",
    "print(snarl_index_somme_pas_ok)\n",
    "for i in snarl_index_somme_pas_ok:\n",
    "    if i in zero_dans_contingence_snarl:\n",
    "        print(i)'''\n",
    "\n",
    "'''    print('--------------------')\n",
    "    print(contingence_pb[i])\n",
    "    print('####################')''';"
   ],
   "id": "ea766e4e752d9784",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "contingence_pb[-5]",
   "id": "bfeb58e1653603ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(table_contingence('79>84'))\n",
    "print(table_contingence('60>71'))\n",
    "print(table_contingence('4>9'))\n",
    "vcf1_df"
   ],
   "id": "3aeb0859ee425101",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pval_pb = [(chi2(table_contingence(i)), i) for i in zero_dans_contingence_snarl]\n",
    "pval_pb = [[chi2(i), 0] for i in contingence_pb]\n",
    "for i in range(len(pval_pb)):\n",
    "    pval_pb[i][1] = zero_dans_contingence_snarl[i]\n",
    "pval_all = pval + pval_pb\n",
    "\n",
    "pval_all_df = create_pval_df(pval_all)\n",
    "for i in pval_all_df.index:\n",
    "    if i not in pv_df_test.index:\n",
    "        pval_all_df.loc[i, 'color'] = \"red\"\n",
    " \n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(14, 8))\n",
    "ax[0][0].hist(pv_df_test['p-valeur'])\n",
    "ax[0][0].set_title('legal pvalues')\n",
    "ax[0][1].hist(pval_all_df['p-valeur'])\n",
    "ax[0][1].set_title('all pvalues')\n",
    "\n",
    "ax[1][0].scatter(range(len(pv_df_test)), pv_df_test['moinslog10pvaleur'], c=pv_df_test['color'])\n",
    "ax[1][0].set_title('legal moins log10 pvalues')\n",
    "ax[1][1].scatter(range(len(pval_all_df)), pval_all_df['moinslog10pvaleur'], c=pval_all_df['color'])\n",
    "ax[1][1].set_title('all moins log10 pvalues')\n",
    "#plt.hist(pval_all)"
   ],
   "id": "decbb9159d9baa23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# proof (pour moi même) that the two df are not identical \n",
    "# par contre trafiquer les tables de contingences n'a pas permis d'avoir de petites pvaleurs \n",
    "print(len(pv_df_test), len(pval_all_df))"
   ],
   "id": "c857dfec27bdf397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## la suite",
   "id": "f75a701ef101955e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # cb de snarls avec n chemins possibles ?\n",
    "from itertools import groupby\n",
    "\n",
    "length_of_paths = []\n",
    "for i in list(snarl_df.index):\n",
    "    length_of_paths.append(list(snarl_df.index).count(i))\n",
    "    \n",
    "# occ = [[x,ind.count(x)] for x in set(ind)]\n",
    "\n",
    "taille_chem = list(set(length_of_paths))\n",
    "freq_taille = [len(list(group)) for key, group in groupby(sorted(length_of_paths))]\n",
    "\n",
    "print(taille_chem, freq_taille)"
   ],
   "id": "c7b0dfc4288b860d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # 'Play' with bdsg\n",
    "##### am i playing with bdsg or is bdsg playing with me"
   ],
   "id": "e08d16e9ffb3ead7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bdsg.bdsg import HashGraph\n",
    "\n",
    "gr = HashGraph()\n",
    "seq = [\"CGA\", \"TTGG\", \"CCGT\", \"C\", \"GT\", \"GATAA\", \"CGG\", \"ACA\", \"GCCG\", \"ATATAAC\"]\n",
    "n = []\n",
    "for s in seq:\n",
    "    n.append(gr.create_handle(s))\n",
    "\n",
    "gr.create_edge(n[0], n[1])\n",
    "gr.create_edge(n[1], n[2])\n",
    "gr.create_edge(n[2], n[3])\n",
    "gr.create_edge(n[2], n[4])\n",
    "gr.create_edge(n[3], n[5])\n",
    "gr.create_edge(n[5], n[6])\n",
    "# Connect the end of n5 to the start of n8\n",
    "gr.create_edge(n[5], n[8])\n",
    "gr.create_edge(n[6], n[7])\n",
    "gr.create_edge(n[6], n[8])\n",
    "gr.create_edge(n[7], n[9])\n",
    "gr.create_edge(n[8], n[9])\n",
    "# Connect the end of n8 back around to the start of n5\n",
    "gr.create_edge(n[8], n[5])\n",
    "\n",
    "def next_node_list(handle):\n",
    "    lis = []\n",
    "    gr.follow_edges(handle, False, lambda y: lis.append(y))\n",
    "    return lis\n",
    "\n",
    "print(n)\n",
    "\n",
    "print(f'n0: {gr.get_sequence(n[0])}')\n",
    "next_node = next_node_list(n[0])[0]\n",
    "print(f'n1: {gr.get_sequence(next_node)}')\n",
    "next_node = next_node_list(next_node)[0]\n",
    "print(f'n2: {gr.get_sequence(next_node)}')\n",
    "\n",
    "path = gr.create_path_handle(\"path\")\n",
    "gr.append_step(path, n[0])\n",
    "gr.append_step(path, n[1])\n",
    "gr.append_step(path, n[2])\n",
    "gr.append_step(path, n[4])\n",
    "gr.append_step(path, n[5])\n",
    "gr.append_step(path, n[6])\n",
    "gr.append_step(path, n[7])\n",
    "gr.append_step(path, n[9])"
   ],
   "id": "9d75cc4da39100ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bdsg.bdsg import PackedGraph\n",
    "brca2 = PackedGraph()\n",
    "brca2.deserialize(\"/home/yboulkaid/Documents/sample_data/pgtest.data/pg.pg\")\n",
    "#brca2.deserialize(\"/home/yboulkaid/Téléchargements/cactus-brca2.pg\")\n",
    "\n",
    "path_handle = []\n",
    "handles = []\n",
    "brca2.for_each_path_handle(lambda y: path_handle.append(y) or True)\n",
    "brca2.for_each_step_in_path(path_handle[0],\n",
    "    lambda y: handles.append(brca2.get_handle_of_step(y)) or True)\n",
    "sequence = \"\"\n",
    "for handle in handles:\n",
    "    sequence += brca2.get_sequence(handle)\n",
    "print(sequence[0:10])\n",
    "print(len(sequence))\n"
   ],
   "id": "d06c1ab3e53d0c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "type(gr)\n",
    "\n",
    "# CACGTCCGAGAATCGG\n",
    "# CACGTCCGAG"
   ],
   "id": "ab7e8f3279144fdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from bdsg.handlegraph import  HandleGraph\n",
    "###########################################\n",
    "### HOW TO ACCESS THE SNARL TREE (XIAN) ###\n",
    "###########################################\n",
    "\n",
    "# load the snarl tree\n",
    "stree = bdsg.bdsg.SnarlDistanceIndex()\n",
    "stree.deserialize(\"pg.dist\")\n",
    "# Note: make the pg.dist from the pg.pg using: vg index -j pg.dist pg.pg\n",
    "\n",
    "# load the graph\n",
    "pg = bdsg.bdsg.PackedGraph()\n",
    "pg.deserialize(\"pg.pg\")\n",
    "\n",
    "## To practice let's save all the nodes in the snarl tree in a list\n",
    "stnodes = []\n",
    "# find the object pointing to the root of the snarl tree\n",
    "root = distance_index.get_root()\n",
    "# the function we want to run on each child of a snarl tree node\n",
    "def save_snarl_tree_node(stnode):\n",
    "    # FILL\n",
    "    #   here for example, save the input in the list and iterate on its potential children\n",
    "    # if the function returns True, the iteration will continue (which is what we want in this case)\n",
    "    return(True)\n",
    "# run that function, starting from the rood node of the tree\n",
    "stree.for_each_child(root, save_snarl_tree_node)\n",
    "# note: for_each_child can only be run on elements that have children (i.e. chains and snarls), not nodes or sentinels.\n",
    "\n",
    "## Understanding elements of the snarl tree\n",
    "# get one of the snarl tree nodes saved earlier\n",
    "stn = stnodes[3]\n",
    "# print it's \"string\" summary\n",
    "stree.net_handle_as_string(stn)\n",
    "# check which type it is\n",
    "stree.is_chain(stn)\n",
    "stree.is_snarl(stn)\n",
    "stree.is_sentinel(stn)\n",
    "stree.is_node(stn)\n",
    "\n",
    "## Manipulating a snarl\n",
    "# assuming we have a snarl, get the boundary nodes\n",
    "stn_start = stree.get_bound(stn, False, True)\n",
    "stn_end = stree.get_bound(stn, True, True)\n",
    "# get the actual node, not the sentinel (~fake boundary nodes?)\n",
    "stn_start = stree.get_node_from_sentinel(stn_start)\n",
    "stn_end = stree.get_node_from_sentinel(stn_end)\n",
    "stn_end = stree.flip(stn_end) # flip the end handle (I think, to be confirmed)\n",
    "# get a node id\n",
    "stree.node_id(stn_start)\n",
    "# get a handle/object of that node in the graph\n",
    "stn_start_pg = stree.get_handle(stn_start, pg)\n",
    "stn_end_pg = stree.get_handle(stn_end, pg)\n",
    "# get the ID of an element in the graph, here a node\n",
    "pg.get_id(stn_start_pg)\n",
    "# test if there is an edge between two nodes in the graph\n",
    "pg.has_edge(stn_start_pg, stn_end_pg)\n"
   ],
   "id": "f69719a46a41b1ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(ngraph)\n",
    "print(distance_index.net_handle_as_string(ngraph['n'][0]))"
   ],
   "id": "6a0b1ee6d5c138a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ngraph['n']",
   "id": "2541def03f6931e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "distance_index.deserialize(\"/home/yboulkaid/Documents/sample_data/pgtest.data/pg.dist\")",
   "id": "2ca5a6a911f6fda8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''get parent \n",
    "get child \n",
    "get bound \n",
    "get root'''"
   ],
   "id": "dc377e78093607ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "801b0b3e04d5210b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
